package com.at.rt.data.warehouse.dwd.order;

import com.at.rt.data.warehouse.StreamExecEnvConf;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

import java.time.Duration;

/**
 * 取消订单事实表
 *
 * @author wenzhilong
 */
public class DWDTradeOrderCancelDetail {

    public static void main(String[] args) {

        StreamTableEnvironment tableEnv = StreamExecEnvConf.builderStreamTableEnv(args);

        // 设置状态的保留时间
        tableEnv.getConfig().setIdleStateRetention(Duration.ofSeconds(30 * 60 + 5));

        String sql = "\n"
                + "-- 从 kafka 的 ODS_BASE_DB 主题中读取数据\n"
                + "CREATE TABLE topic_db (\n"
                + "    `database` string,\n"
                + "    `table` string,\n"
                + "    `type` string,\n"
                + "    `ts` bigint,\n"
                + "    `data` MAP<string, string>,\n"
                + "    `old` MAP<string, string>,\n"
                + "    pt as proctime(),\n"
                + "    et as to_timestamp_ltz(ts, 0), \n"
                + "    watermark for et as et - interval '3' second \n"
                + ") \n"
                + "WITH \n"
                + "(\n"
                + "    'connector' = 'kafka',\n"
                + "    'topic' = 'ODS_BASE_DB',\n"
                + "    'properties.bootstrap.servers' = 'hadoop102:9092,hadoop103:9092,hadoop104:9092',\n"
                + "    'properties.group.id' = 'DWDTradeOrderCancelDetail',\n"
                + "    'scan.startup.mode' = 'earliest-offset',\n"
                + "    'format' = 'json'\n"
                + ")\n"
                + ";\n"
                + "\n"
                + "-- 过滤出取消订单行为\n"
                + "create temporary view order_cancel as \n"
                + "select \n"
                + "    `data`['id'] id, \n"
                + "    `data`['operate_time'] operate_time, \n"
                + "    `ts` \n"
                + "from topic_db \n"
                + "where `table`='order_info' \n"
                + "and `type`='update' \n"
                + "and `old`['order_status']='1001' \n"
                + "and `data`['order_status']='1003'\n"
                + ";\n"
                + "\n"
                + "-- 从下单事实表中获取下单数据\n"
                + "create table dwd_trade_order_detail(\n"
                + "    id string,\n"
                + "    order_id string,\n"
                + "    user_id string,\n"
                + "    sku_id string,\n"
                + "    sku_name string,\n"
                + "    province_id string,\n"
                + "    activity_id string,\n"
                + "    activity_rule_id string,\n"
                + "    coupon_id string,\n"
                + "    date_id string,\n"
                + "    create_time string,\n"
                + "    sku_num string,\n"
                + "    split_original_amount string,\n"
                + "    split_activity_amount string,\n"
                + "    split_coupon_amount string,\n"
                + "    split_total_amount string,\n"
                + "    ts bigint \n"
                + ")\n"
                + "WITH \n"
                + "(\n"
                + "    'connector' = 'kafka',\n"
                + "    'topic' = 'dwd_trade_order_detail',\n"
                + "    'properties.bootstrap.servers' = 'hadoop102:9092',\n"
                + "    'properties.group.id' = 'dwd_trade_order_cancel',\n"
                + "    'scan.startup.mode' = 'earliest-offset',\n"
                + "    'format' = 'json'\n"
                + ")\n"
                + ";\n"
                + "\n"
                + "-- sink\n"
                + "create table dwd_trade_order_cancel (\n"
                + "    id string,\n"
                + "    order_id string,\n"
                + "    user_id string,\n"
                + "    sku_id string,\n"
                + "    sku_name string,\n"
                + "    province_id string,\n"
                + "    activity_id string,\n"
                + "    activity_rule_id string,\n"
                + "    coupon_id string,\n"
                + "    date_id string,\n"
                + "    cancel_time string,\n"
                + "    sku_num string,\n"
                + "    split_original_amount string,\n"
                + "    split_activity_amount string,\n"
                + "    split_coupon_amount string,\n"
                + "    split_total_amount string,\n"
                + "    ts bigint ,\n"
                + "    PRIMARY KEY (id) NOT ENFORCED \n"
                + ")\n"
                + "WITH \n"
                + "(\n"
                + "    'connector' = 'upsert-kafka',\n"
                + "    'topic' = 'dwd_trade_order_cancel',\n"
                + "    'properties.bootstrap.servers' = 'hadoop102:9092,hadoop103:9092,hadoop104:9092',\n"
                + "    'key.format' = 'json',\n"
                + "    'value.format' = 'json'\n"
                + ")\n"
                + ";\n"
                + "\n"
                + "-- 将下单事实表和取消订单表进行关联\n"
                + "insert into dwd_trade_order_cancel \n"
                + "select  \n"
                + "    od.id,\n"
                + "    od.order_id,\n"
                + "    od.user_id,\n"
                + "    od.sku_id,\n"
                + "    od.sku_name,\n"
                + "    od.province_id,\n"
                + "    od.activity_id,\n"
                + "    od.activity_rule_id,\n"
                + "    od.coupon_id,\n"
                + "    date_format(oc.operate_time, 'yyyy-MM-dd') order_cancel_date_id,\n"
                + "    oc.operate_time,\n"
                + "    od.sku_num,\n"
                + "    od.split_original_amount,\n"
                + "    od.split_activity_amount,\n"
                + "    od.split_coupon_amount,\n"
                + "    od.split_total_amount,\n"
                + "    oc.ts \n"
                + "from dwd_trade_order_detail od \n"
                + "join order_cancel oc \n"
                + "on od.order_id=oc.id\n"
                + ";";

        StreamExecEnvConf.execSQL(tableEnv,sql);
    }
}
