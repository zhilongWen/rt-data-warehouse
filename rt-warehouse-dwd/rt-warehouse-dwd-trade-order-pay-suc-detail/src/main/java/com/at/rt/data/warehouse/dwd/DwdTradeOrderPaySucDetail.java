package com.at.rt.data.warehouse.dwd;

import com.at.rt.data.warehouse.StreamExecEnvConf;
import org.apache.flink.table.api.bridge.java.StreamTableEnvironment;

/**
 * DwdTradeOrderPaySucDetail
 *
 * @author wenzhilong
 */
public class DwdTradeOrderPaySucDetail {

    public static void main(String[] args) {

        StreamTableEnvironment tableEnv = StreamExecEnvConf.builderStreamTableEnv(args);

        String sql = "-- 从下单事实表读取数据 创建动态表\n"
                + "create table dwd_trade_order_detail(\n"
                + "    id string,\n"
                + "    order_id string,\n"
                + "    user_id string,\n"
                + "    sku_id string,\n"
                + "    sku_name string,\n"
                + "    province_id string,\n"
                + "    activity_id string,\n"
                + "    activity_rule_id string,\n"
                + "    coupon_id string,\n"
                + "    date_id string,\n"
                + "    create_time string,\n"
                + "    sku_num string,\n"
                + "    split_original_amount string,\n"
                + "    split_activity_amount string,\n"
                + "    split_coupon_amount string,\n"
                + "    split_total_amount string,\n"
                + "    ts bigint,\n"
                + "    et as to_timestamp_ltz(ts, 0), \n"
                + "    watermark for et as et - interval '3' second \n"
                + ")\n"
                + "WITH (\n"
                + "    'connector' = 'kafka',\n"
                + "    'topic' = 'dwd_trade_order_detail',\n"
                + "    'properties.bootstrap.servers' = 'hadoop102:9092',\n"
                + "    'properties.group.id' = 'DwdTradeOrderPaySucDetail',\n"
                + "    'scan.startup.mode' = 'earliest-offset',\n"
                + "    'format' = 'json'\n"
                + ")\n"
                + ";\n"
                + "\n"
                + "-- 从 ODS_BASE_DB 主题中读取数据  创建动态表\n"
                + "CREATE TABLE topic_db (\n"
                + "    `database` string, \n"
                + "    `table` string,\n"
                + "    `type` string,\n"
                + "    `ts` bigint,\n"
                + "    `data` MAP<string, string>,\n"
                + "    `old` MAP<string, string>,\n"
                + "    pt as proctime(),\n"
                + "    et as to_timestamp_ltz(ts, 0), \n"
                + "    watermark for et as et - interval '3' second \n"
                + ")\n"
                + "WITH (\n"
                + "    'connector' = 'kafka',\n"
                + "    'topic' = 'ODS_BASE_DB',\n"
                + "    'properties.bootstrap.servers' = 'hadoop102:9092,hadoop103:9092,hadoop104:9092',\n"
                + "    'properties.group.id' = 'DwdTradeOrderDetail',  \n"
                + "    'scan.startup.mode' = 'earliest-offset',\n"
                + "    'format' = 'json'\n"
                + ")\n"
                + ";\n"
                + "\n"
                + "-- 过滤出支付成功数据\n"
                + "create temporary view payment_info as\n"
                + "select \n"
                + "    data['user_id'] user_id,\n"
                + "    data['order_id'] order_id,\n"
                + "    data['payment_type'] payment_type,\n"
                + "    data['callback_time'] callback_time,\n"
                + "    `pt`,\n"
                + "    ts, \n"
                + "    et \n"
                + "from topic_db \n"
                + "where `table`='payment_info' \n"
                + "and `type`='update' \n"
                + "and `old`['payment_status'] is not null \n"
                + "and `data`['payment_status']='1602' \n"
                + ";\n"
                + "\n"
                + "-- 从HBase中读取字典数据 创建动态表\n"
                + "CREATE TABLE base_dic (\n"
                + "    dic_code string,\n"
                + "    info ROW<dic_name string>,\n"
                + "    PRIMARY KEY (dic_code) NOT ENFORCED\n"
                + ")\n"
                + "WITH \n"
                + "(\n"
                + "    'connector' = 'hbase-2.2',\n"
                + "    'table-name' = 'gmall:dim_base_dic',\n"
                + "    'zookeeper.quorum' = 'hadoop102:2181',\n"
                + "    'lookup.async' = 'true',\n"
                + "    'lookup.cache' = 'PARTIAL',\n"
                + "    'lookup.partial-cache.max-rows' = '500',\n"
                + "    'lookup.partial-cache.expire-after-write' = '1 hour',\n"
                + "    'lookup.partial-cache.expire-after-access' = '1 hour'\n"
                + ")\n"
                + ";\n"
                + "\n"
                + "-- sink\n"
                + "create table dwd_trade_order_payment_success (\n"
                + "    order_detail_id string,\n"
                + "    order_id string,\n"
                + "    user_id string,\n"
                + "    sku_id string,\n"
                + "    sku_name string,\n"
                + "    province_id string,\n"
                + "    activity_id string,\n"
                + "    activity_rule_id string,\n"
                + "    coupon_id string,\n"
                + "    payment_type_code string,\n"
                + "    payment_type_name string,\n"
                + "    callback_time string,\n"
                + "    sku_num string,\n"
                + "    split_original_amount string,\n"
                + "    split_activity_amount string,\n"
                + "    split_coupon_amount string,\n"
                + "    split_payment_amount string,\n"
                + "    ts bigint ,\n"
                + "    PRIMARY KEY (order_detail_id) NOT ENFORCED \n"
                + ")\n"
                + "WITH \n"
                + "(\n"
                + "    'connector' = 'upsert-kafka',\n"
                + "    'topic' = 'dwd_trade_order_payment_success',\n"
                + "    'properties.bootstrap.servers' = 'hadoop102:9092',\n"
                + "    'key.format' = 'json',\n"
                + "    'value.format' = 'json'\n"
                + ")\n"
                + ";\n"
                + "\n"
                + "-- 和字典进行关联---lookup join 和下单数据进行关联---IntervalJoin\n"
                + "insert into dwd_trade_order_payment_success\n"
                + "select \n"
                + "    od.id order_detail_id,\n"
                + "    od.order_id,\n"
                + "    od.user_id,\n"
                + "    od.sku_id,\n"
                + "    od.sku_name,\n"
                + "    od.province_id,\n"
                + "    od.activity_id,\n"
                + "    od.activity_rule_id,\n"
                + "    od.coupon_id,\n"
                + "    pi.payment_type payment_type_code ,\n"
                + "    dic.dic_name payment_type_name,\n"
                + "    pi.callback_time,\n"
                + "    od.sku_num,\n"
                + "    od.split_original_amount,\n"
                + "    od.split_activity_amount,\n"
                + "    od.split_coupon_amount,\n"
                + "    od.split_total_amount split_payment_amount,\n"
                + "    pi.ts \n"
                + "from payment_info pi \n"
                + "join dwd_trade_order_detail od \n"
                + "    on pi.order_id = od.order_id and od.et >= pi.et - interval '30' minute and od.et <= pi.et + interval '5' second \n"
                + "join base_dic for system_time as of pi.pt as dic \n"
                + "    on pi.payment_type=dic.dic_code\n"
                + ";";

        StreamExecEnvConf.execSQL(tableEnv, sql);
    }
}
