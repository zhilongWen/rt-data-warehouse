isLocal: true

# Flink Execute Environment
execute:
  env:
    - streaming
    - batch

rest:
  port: 9099

pipeline:
  operator-chaining: false

default:
  parallelism: 1

restart:
  strategy:
    - fix:
        attempts: 3
        delay: 60000 # ms

checkpoint:
  enable: true
  type: AT_LEAST_ONCE # 1 AT_LEAST_ONCE 0  EXACTLY_ONCE
  unaligned: false # EXACTLY_ONCE 模式下这里设置 true 才有意义 Unaligned checkpoints are currently not supported for custom partitioners, as rescaling is not guaranteed to work correctly. The user can force Unaligned Checkpoints by using 'execution.checkpointing.unaligned.forced'
  interval: 5000 # ms
  min-between: 500 # ms
  timeout: 5000 # ms
  failure-num: 5
  state-storage: filesystem
  state-dir: hdfs://hadoop102:8020/rt/checkpoint/DWSTrafficSourceKeywordPageViewWindow

sql: |
  SET 'table.exec.resource.default-parallelism' = '5';
  SET 'table.exec.source.idle-timeout' = '1000';
  
  
  -- 从页面日志事实表中读取数据 创建动态表  并指定Watermark的生成策略以及提取事件时间字段
  create table page_log(
  common map<string,string>,
  page map<string,string>,
  ts bigint,
  et as TO_TIMESTAMP_LTZ(ts, 3),
  WATERMARK FOR et AS et
  )WITH (
  'connector' = 'kafka',
  'topic' = 'dwd_traffic_page',
  'properties.bootstrap.servers' = 'hadoop102:9092',
  'properties.group.id' = 'DwsTrafficSourceKeywordPageViewWindow',
  'scan.startup.mode' = 'earliest-offset',
  'format' = 'json'
  )
  ;
  
  -- 过滤出搜索行为
  create temporary view search_table as
  select
  page['item']  fullword,
  et
  from page_log
  where page['last_page_id'] = 'search' and page['item_type'] ='keyword' and page['item'] is not null
  ;
  
  -- 调用自定义函数完成分词   并和原表的其它字段进行join
  create temporary view split_table as
  SELECT
  keyword,
  et
  FROM search_table,
  LATERAL TABLE(ik_analyze(fullword)) t(keyword)
  ;
  
  -- sink
  create table dws_traffic_source_keyword_page_view_window(
  stt string,   -- 2023-07-11 14:14:14
  edt string,
  cur_date string,
  keyword string,
  keyword_count bigint
  )with(
  'connector' = 'doris',
  'fenodes' = '10.211.55.102:7030',
  'table.identifier' = 'gmall_realtime.dws_traffic_source_keyword_page_view_window',
  'username' = 'root',
  'password' = 'root123',
  'sink.properties.format' = 'json',
  'sink.buffer-count' = '4',
  'sink.buffer-size' = '4086',
  'sink.enable-2pc' = 'false',  -- 测试阶段可以关闭两阶段提交,方便测试
  'sink.properties.read_json_by_line' = 'true'
  )
  ;
  
  -- 分组、开窗、聚合 将聚合的结果写到Doris中
  insert into dws_traffic_source_keyword_page_view_window
  SELECT
  date_format(window_start, 'yyyy-MM-dd HH:mm:ss') stt,
  date_format(window_end, 'yyyy-MM-dd HH:mm:ss') edt,
  date_format(window_start, 'yyyy-MM-dd') cur_date,
  keyword,
  count(*) keyword_count
  FROM TABLE
  (
  TUMBLE(TABLE split_table, DESCRIPTOR(et), INTERVAL '10' second)
  )
  GROUP BY window_start, window_end,keyword
  ;


  